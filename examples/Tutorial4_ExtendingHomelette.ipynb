{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# Tutorial 4: Extending homelette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import homelette as hm\n",
    "\n",
    "import contextlib\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "from modeller import environ, Selection\n",
    "from modeller.automodel import LoopModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the forth tutorial on `homelette`. In this tutorial, we will discuss how to implement custom building blocks, either for generating or for evaluating models. These custom building blocks can be integrated in homology modelling pipelines.\n",
    "\n",
    "This is probably the most important tutorial in the series. After this tutorial, you will be able to implement your own routines into the `homelette` framework, which gives you complete control over the homology modelling pipelines you want to establish!\n",
    "\n",
    "Please note that we encourage users to share custom routines and evaluation metrics if they think they might be useful for the community. In our [online documentation](https://homelette.readthedocs.io/), there is a dedicated section for these contributions. If you are interested, please contact us on [GitHub](https://github.com/PhilippJunk/homelette) or via [email](mailto:philipp.junk@ucdconnect.ie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we are using the same alignment as in **Tutorial 1**. Identical to **Tutorial 1**, the alignment is imported and annotated and a `Task` object is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the alignment\n",
    "aln = hm.Alignment('data/single/aln_1.fasta_aln')\n",
    "\n",
    "# annotate the alignment\n",
    "aln.get_sequence('ARAF').annotate(\n",
    "    seq_type = 'sequence')\n",
    "aln.get_sequence('3NY5').annotate(\n",
    "    seq_type = 'structure',\n",
    "    pdb_code = '3NY5',\n",
    "    begin_res = '1',\n",
    "    begin_chain = 'A',\n",
    "    end_res = '81', \n",
    "    end_chain = 'A')\n",
    "\n",
    "# initialize task object\n",
    "t = hm.Task(\n",
    "    task_name = 'Tutorial4',\n",
    "    target = 'ARAF',\n",
    "    alignment = aln,\n",
    "    overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining custom routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example for a custom routine, we will implement a `LoopModel` class from `modeller` [1,2] loosely following [this tutorial](https://salilab.org/modeller/tutorial/advanced.html) on the `modeller` web page (in the section **Loop Refining**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Routine_loopmodel(hm.routines.Routine): # (1)\n",
    "    '''\n",
    "    Custom routine for modeller loop modelling.\n",
    "    '''\n",
    "    def __init__(self, alignment, target, templates, tag, n_models=1, n_loop_models=1): # (2)\n",
    "        hm.routines.Routine.__init__(self, alignment, target, templates, tag)\n",
    "        self.routine = 'loopmodel' # string identifier of routine\n",
    "        \n",
    "        self.n_models = n_models\n",
    "        self.n_loop_models = n_loop_models\n",
    "    \n",
    "    def generate_models(self): # (3)\n",
    "        # (4) process alignment\n",
    "        self.alignment.select_sequences([self.target] + self.templates)\n",
    "        self.alignment.remove_redundant_gaps()\n",
    "        # write alignemnt to temporary file\n",
    "        self.alignment.write_pir('.tmp.pir')\n",
    "        \n",
    "        # (5) define custom loop model class\n",
    "        class MyLoop(LoopModel):\n",
    "            # set residues that will be refined by loop modelling\n",
    "            def select_loop_atoms(self):\n",
    "                return Selection(self.residue_range('18:A', '22:A'))\n",
    "        \n",
    "        with contextlib.redirect_stdout(None): # (6) suppress modeller output to stdout\n",
    "            # (7) set up modeller environment\n",
    "            env = environ()\n",
    "            env.io.hetatm = True\n",
    "\n",
    "            # initialize model\n",
    "            m = MyLoop(env,\n",
    "                       alnfile='.tmp.pir',\n",
    "                       knowns=self.templates,\n",
    "                       sequence=self.target)\n",
    "\n",
    "            # set modelling parameters\n",
    "            m.blank_single_chain = False\n",
    "            m.starting_model = 1\n",
    "            m.ending_model = self.n_models\n",
    "            m.loop.starting_model = 1\n",
    "            m.loop.ending_model = self.n_loop_models\n",
    "\n",
    "            # make models\n",
    "            m.make()\n",
    "        \n",
    "        # (8) capture output\n",
    "        for pdb in glob.glob('{}.BL*.pdb'.format(self.target)):\n",
    "            self.models.append(\n",
    "                hm.Model(os.path.realpath(os.path.expanduser(pdb)),\n",
    "                         self.tag, self.routine))\n",
    "        \n",
    "        # (9) rename files with method from hm.routines.Routine\n",
    "        self._rename_models()\n",
    "        \n",
    "        # (10) clean up\n",
    "        self._remove_files(\n",
    "            '{}.B99*.pdb'.format(self.target),\n",
    "            '{}.D00*'.format(self.target),\n",
    "            '{}.DL*'.format(self.target),\n",
    "            '{}.IL*'.format(self.target),\n",
    "            '{}.ini'.format(self.target),\n",
    "            '{}.lrsr'.format(self.target),\n",
    "            '{}.rsr'.format(self.target),\n",
    "            '{}.sch'.format(self.target),\n",
    "            '.tmp*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines of code in the definition of the custom routine above that are marked with numbers get special comments here:\n",
    "\n",
    "1. Our custom routine in this example inherits from a parent class `Routine` defined in `homelette`. This is not strictly necessary, however, the parent class has a few useful functions already implemented that we will make use of (see steps 2, 9, 10)\n",
    "2. Every routine needs to accept these arguments: `alignment`, `target`, `templates`, `tag`. In our case, we just hand them through to the parent method `Routine.__init__` that saves them as attributes, as well as introduces the attribute `self.models` where models will be deposited after generation. \n",
    "3. Every routine needs a `generate_models` method. Usually, functionality for, you guessed it, model generation is packed in there.\n",
    "4. `modeller` requires the aligment as a file in PIR format. The following few lines of code format the alignment and then produce the required file.\n",
    "5. The following lines follow closely the `modeller` [tutorial](https://salilab.org/modeller/tutorial/advanced.html) for loop modelling. This part implements a custom `LoopModel` class that defines a specific set of residue to be considered for loop modelling.\n",
    "6. `modeller` writes a lot of output to stdout, and using `contextlib` is a way to suppress this output. If you want to see all the output from `modeller`, either delete the `with` statement or write `with contextlib.redirect_stdout(sys.stdout):` instead.\n",
    "7. The following lines follow closely the `modeller` [tutorial](https://salilab.org/modeller/tutorial/advanced.html) for loop modelling. This part initializes the model and generates the models requested.\n",
    "8. The final models generated will be called `ARAF.BL00010001.pdb` and so on. These lines of code find these PDB files and add them to the `Routine_loopmodel.models` list as `Model`s. After execution by a `Task` objects, `Model` objects in this list will be added to the `Task.models` list.\n",
    "9. Models generated will be renamed according to the tag given using the parent class method `Routine._rename_models`.\n",
    "10. Temporary files from modeller as well as the temporary alignment file are removed from the folder using the parent class method `Routine._remove_files`.\n",
    "\n",
    "---\n",
    "\n",
    "Now, after implementing the routine, let's try it out in practice. As explained in **Tutorial 2**, we will be using the `Task.execute_routine` interface for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform modelling\n",
    "t.execute_routine(\n",
    "    tag = 'custom_loop',\n",
    "    routine = Routine_loopmodel,\n",
    "    templates = ['3NY5'],\n",
    "    template_location = './data/single',\n",
    "    n_models = 2,\n",
    "    n_loop_models = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<homelette.organization.Model at 0x7f8322cf6e80>,\n",
       " <homelette.organization.Model at 0x7f8322cf64f0>,\n",
       " <homelette.organization.Model at 0x7f8322c378b0>,\n",
       " <homelette.organization.Model at 0x7f8322c37880>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check generated models\n",
    "t.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, a valid routine only needs to adhere to a small number of formal criteria to fit in the `homelette` framework:\n",
    "\n",
    "- It needs to be an object.\n",
    "- It needs to have an `__init__` method that can handle the named arguments `alignment`, `target`, `templates` and `tag`.\n",
    "- It needs a `generate_models` method.\n",
    "- It needs an attribute `models` in which generated models are stored as `Model` objects in list.\n",
    "\n",
    "Any object that satisfies these criteria can be used in the framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining custom evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example for a custom evaluation, we will implement a sample evaluation that counts the number of residues in the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation_countresidues():\n",
    "    '''\n",
    "    Custom evaluation: counting CA atoms\n",
    "    '''\n",
    "    def __init__(self, model, quiet=True): # (1)\n",
    "        self.model = model\n",
    "        self.output = dict()\n",
    "        # (2) perform evaluation\n",
    "        self.evaluate()\n",
    "        # (3) update model.evaluation\n",
    "        self.model.evaluation.update(self.output) \n",
    "    \n",
    "    def evaluate(self): # (4)\n",
    "        # (5) parse model pdb\n",
    "        pdb = self.model.parse_pdb()\n",
    "        \n",
    "        # count number of CA atoms in PDB\n",
    "        n_residues = pdb['name'].eq('CA').sum()\n",
    "        \n",
    "        # append to output\n",
    "        self.output['n_residues'] = n_residues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines of code marked with numbers in the definiton of the custom evaluation get special comments here:\n",
    "\n",
    "1. The `__init__` function takes exactly 2 arguments: `model` and `quiet`. `quiet` is a boolean value indicating whether output to stdout should be suppressed (not applicable in this case).\n",
    "2. All evaluation metrics are executed upon initialization.\n",
    "3. The `custom_evaluation.output` dictionary is merged with the `Model.evaluation` dictionary to make the output of our evaluation metrics available to the model. \n",
    "4. Here we define the function where the actual evaluation takes place.\n",
    "5. For the actual evaluation, we make use of the `Model.parse_pdb` method, which parses the PDB file associated to a specific model object to a `pandas` data frame. This can be useful for a number of evaluations (access residues, coordinates, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "If more arguments are required for a custom evaluation, we recomment to store them as attributes in the `Model` objects and then access these attributes while running the evaluation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply our custom evaluation to our previously generated models using the `Task.evaluate_models` interface (for more details, see **Tutorial 3**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tag</th>\n",
       "      <th>routine</th>\n",
       "      <th>n_residues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custom_loop_1.pdb</td>\n",
       "      <td>custom_loop</td>\n",
       "      <td>loopmodel</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>custom_loop_2.pdb</td>\n",
       "      <td>custom_loop</td>\n",
       "      <td>loopmodel</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>custom_loop_3.pdb</td>\n",
       "      <td>custom_loop</td>\n",
       "      <td>loopmodel</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>custom_loop_4.pdb</td>\n",
       "      <td>custom_loop</td>\n",
       "      <td>loopmodel</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model          tag    routine  n_residues\n",
       "0  custom_loop_1.pdb  custom_loop  loopmodel          73\n",
       "1  custom_loop_2.pdb  custom_loop  loopmodel          73\n",
       "2  custom_loop_3.pdb  custom_loop  loopmodel          73\n",
       "3  custom_loop_4.pdb  custom_loop  loopmodel          73"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.evaluate_models(Evaluation_countresidues)\n",
    "t.get_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In practice, the formal requirements for a custom evaluation are the following:\n",
    "\n",
    "- It has to be an object.\n",
    "- `__init__` has the two arguments `model` and `quiet`. More arguments would work in conjunction with `Task.evaluate_models` only if defaults are set and used. We recommend storing more arguments as attributes in the `Model` object and then accessing them during the evaluation.\n",
    "- It executes evaluation on initialization.\n",
    "- On finishing the evaluation, it updates the `Model.evaluation` dictionary with the results of the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing the tutorial on extending `homelette`. \n",
    "\n",
    "Please take again notice that on our [online documentation](https://homelette.readthedocs.io/), there is a page collecting user-submitted custom routines and evaluation metrics. User are encouraged to share if they implemented something which they might think could be useful for the community. If you are interested, please contact us on [GitHub](https://github.com/PhilippJunk/homelette) or via [email](mailto:philipp.junk@ucdconnect.ie).\n",
    "\n",
    "There are more tutorials which might interest you: \n",
    "\n",
    "- **Tutorial 1**: Learn about the basics of `homelette`.\n",
    "- **Tutorial 2**: Learn more about already implemented routines for homology modelling.\n",
    "- **Tutorial 3**: Learn about the evaluation metrics available with `homelette`.\n",
    "- **Tutorial 5**: Learn about how to use parallelization in order to generate and evaluate models more efficiently.\n",
    "- **Tutorial 6**: Learn about modelling protein complexes.\n",
    "- **Tutorial 7**: Learn about assembling custom pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Šali, A., & Blundell, T. L. (1993). Comparative protein modelling by satisfaction of spatial restraints. Journal of Molecular Biology, 234(3), 779–815. https://doi.org/10.1006/jmbi.1993.1626\n",
    "\n",
    "[2] Webb, B., & Sali, A. (2016). Comparative Protein Structure Modeling Using MODELLER. Current Protocols in Bioinformatics, 54(1), 5.6.1-5.6.37. https://doi.org/10.1002/cpbi.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "homelette           1.0\n",
      "modeller            10.1\n",
      "pandas              0.25.3\n",
      "session_info        1.0.0\n",
      "-----\n",
      "PIL                         7.0.0\n",
      "altmod                      NA\n",
      "anyio                       NA\n",
      "attr                        19.3.0\n",
      "babel                       2.9.1\n",
      "backcall                    0.2.0\n",
      "certifi                     2021.05.30\n",
      "chardet                     3.0.4\n",
      "charset_normalizer          2.0.4\n",
      "cycler                      0.10.0\n",
      "cython_runtime              NA\n",
      "dateutil                    2.7.3\n",
      "debugpy                     1.4.1\n",
      "decorator                   4.4.2\n",
      "entrypoints                 0.3\n",
      "idna                        3.2\n",
      "ipykernel                   6.3.1\n",
      "ipython_genutils            0.2.0\n",
      "jedi                        0.18.0\n",
      "jinja2                      3.0.1\n",
      "json5                       NA\n",
      "jsonschema                  3.2.0\n",
      "jupyter_server              1.10.2\n",
      "jupyterlab_server           2.8.0\n",
      "kiwisolver                  1.0.1\n",
      "markupsafe                  2.0.1\n",
      "matplotlib                  3.1.2\n",
      "mpl_toolkits                NA\n",
      "nbclassic                   NA\n",
      "nbformat                    5.1.3\n",
      "numpy                       1.17.4\n",
      "ost                         2.2.0\n",
      "packaging                   20.3\n",
      "parso                       0.8.2\n",
      "pexpect                     4.8.0\n",
      "pickleshare                 0.7.5\n",
      "pkg_resources               NA\n",
      "prometheus_client           NA\n",
      "promod3                     3.2.0\n",
      "prompt_toolkit              3.0.20\n",
      "ptyprocess                  0.7.0\n",
      "pvectorc                    NA\n",
      "pydev_ipython               NA\n",
      "pydevconsole                NA\n",
      "pydevd                      2.4.1\n",
      "pydevd_concurrency_analyser NA\n",
      "pydevd_file_utils           NA\n",
      "pydevd_plugins              NA\n",
      "pydevd_tracing              NA\n",
      "pygments                    2.10.0\n",
      "pyparsing                   2.4.6\n",
      "pyrsistent                  NA\n",
      "pytz                        2019.3\n",
      "qmean                       NA\n",
      "requests                    2.26.0\n",
      "send2trash                  NA\n",
      "sitecustomize               NA\n",
      "six                         1.14.0\n",
      "sniffio                     1.2.0\n",
      "storemagic                  NA\n",
      "swig_runtime_data4          NA\n",
      "terminado                   0.12.1\n",
      "tornado                     6.1\n",
      "traitlets                   5.1.0\n",
      "urllib3                     1.26.6\n",
      "wcwidth                     NA\n",
      "websocket                   1.2.1\n",
      "zmq                         22.2.1\n",
      "-----\n",
      "IPython             7.27.0\n",
      "jupyter_client      7.0.2\n",
      "jupyter_core        4.7.1\n",
      "jupyterlab          3.1.10\n",
      "notebook            6.4.3\n",
      "-----\n",
      "Python 3.8.10 (default, Jun  2 2021, 10:49:15) [GCC 9.4.0]\n",
      "Linux-4.15.0-147-generic-x86_64-with-glibc2.29\n",
      "-----\n",
      "Session information updated at 2021-09-07 15:44\n"
     ]
    }
   ],
   "source": [
    "# session info\n",
    "import session_info\n",
    "session_info.show(html = False, dependencies = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
