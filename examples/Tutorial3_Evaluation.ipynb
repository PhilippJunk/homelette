{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import homelette as hm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the third tutorial for `homelette`. In this tutorial, we will explore which evaluation metrics are implemented in `homelette` and how to use them. \n",
    "\n",
    "Model evaluation is an important step in any homology modelling procedure. In most practical scenarios, you will end up with more than one possible model and have to decide which one is \"best\". Obtaining multiple models can be the result of trying out different templates or combinations of templates, different algorithms generating the models, or due to using an algorithm which can generate multiple models.\n",
    "\n",
    "The following evaluation metrics are implemented in `homelette`:\n",
    "\n",
    "- `evaluation.Evaluation_dope`: DOPE score from `modeller` [1]\n",
    "- `evaluation.Evaluation_soap_protein`: SOAP score from `modeller` for the evaluation of single proteins [2]\n",
    "- `evaluation.Evaluation_soap_pp`: SOAP score from `modeller` for the evaluation of protein complexes [2]\n",
    "- `evaluation.Evaluation_qmean4`: QMEAN4 score [3,4]\n",
    "- `evaluation.Evaluation_qmean6`: QMEAN6 score [3,4]\n",
    "- `evaluation.Evaluation_qmeandisco`: QMEAN DisCo score [3,4,5]\n",
    "- `evaluation.Evaluation_mol_probity`: MolProbity score for the structural evaluation of proteins [6,7,8]\n",
    "\n",
    "All files necessary for running this tutorial are already prepared and deposited in the following directory: `homelette/example/data/`. If you execute this tutorial from `homelette/example/`, you don't have to adapt any of the paths.\n",
    "\n",
    "`homelette` comes with an extensive documentation. You can either check out our [online documentation](https://homelette.readthedocs.io/), compile a local version of the documentation in `homelette/docs/` with `sphinx` or use the `help()` function in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generation\n",
    "\n",
    "In order to have a few models to evaluate, we will briefly generate some models of ARAF as we have done in previous tutorials (please check **Tutorial 1** and **Tutorial 2** for more information on this part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get alignment\n",
    "aln = hm.Alignment('data/single/aln_1.fasta_aln')\n",
    "\n",
    "# annotate the alignment\n",
    "aln.get_sequence('ARAF').annotate(\n",
    "    seq_type = 'sequence')\n",
    "aln.get_sequence('3NY5').annotate(\n",
    "    seq_type = 'structure',\n",
    "    pdb_code = '3NY5',\n",
    "    begin_res = '1',\n",
    "    begin_chain = 'A',\n",
    "    end_res = '81', \n",
    "    end_chain = 'A')\n",
    "\n",
    "# initialize task object\n",
    "t = hm.Task(\n",
    "    task_name = 'Tutorial3',\n",
    "    target = 'ARAF',\n",
    "    alignment = aln,\n",
    "    overwrite = True)\n",
    "\n",
    "# generate models with modeller\n",
    "t.execute_routine(\n",
    "    tag = 'modeller',\n",
    "    routine = hm.routines.Routine_automodel_default,\n",
    "    templates = ['3NY5'],\n",
    "    template_location = './data/single',\n",
    "    n_models = 5)\n",
    "\n",
    "# generate models with altmod\n",
    "t.execute_routine(\n",
    "    tag = 'altmod',\n",
    "    routine = hm.routines.Routine_altmod_default,\n",
    "    templates = ['3NY5'],\n",
    "    template_location = './data/single',\n",
    "    n_models = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have generated 10 models, 5 generated with `modeller` and another 5 generated with `altmod`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation using `evaluation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to routines, evaluations can be executed on their own, although it is recommended to use an interface through the `Task` object (see next section). For showcasing how an evaluation can be executed on its own, we will take one of the previously generated models as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<homelette.organization.Model at 0x7faad444b820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example model\n",
    "model = t.models[0]\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every `Model` object has an `Model.evaluation` attribute where information about the model and its evaluations are collected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'modeller_1.pdb', 'tag': 'modeller', 'routine': 'automodel_default'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing an evaluation, this dictionary will be updated with the results of the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'modeller_1.pdb',\n",
       " 'tag': 'modeller',\n",
       " 'routine': 'automodel_default',\n",
       " 'dope': -7216.8564453125,\n",
       " 'dope_z_score': -1.5211129532811163}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.evaluation.Evaluation_dope(model, quiet=True)\n",
    "model.evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interface to evaluations is relatively simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mhm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluation_dope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquiet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Class for evaluating a model with DOPE score.\n",
       "\n",
       "Will dump the following entries to the model.evaluation dictionary:\n",
       "\n",
       "* dope\n",
       "* dope_z_score\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "model : Model\n",
       "    The model object to evaluate\n",
       "quiet : bool\n",
       "    If True, will perform evaluation with suppressing stdout (default\n",
       "    False). Needs to be False for running it asynchronously, as done\n",
       "    when running Task.evaluate_models with multple cores\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "model : Model\n",
       "    The model object to evaluate\n",
       "output : dict\n",
       "    Dictionary that all outputs will be dumped into\n",
       "\n",
       "Raises\n",
       "------\n",
       "ImportError\n",
       "    Unable to import dependencies\n",
       "\n",
       "Notes\n",
       "-----\n",
       "DOPE is a staticial potential for the evaluation of homology models [1]_.\n",
       "For further information, please check the modeller documentation or the\n",
       "associated publication.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] Shen, M., & Sali, A. (2006). Statistical potential for assessment\n",
       "   and prediction of protein structures. Protein Science, 15(11),\n",
       "   2507â€“2524. https://doi.org/10.1110/ps.062416606\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/src/homelette/homelette/evaluation.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hm.evaluation.Evaluation_dope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluations take only two arguments:\n",
    "- `model`: A `Model` object\n",
    "- `quiet`: A boolean value determining whether any output to the console should be suppressed.\n",
    "\n",
    "Unlike routines, evaluations are executed as soon as the object is initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation using `Task` and `evaluation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the interface to evaluations that is implemented in `Task` objects has several advantages: it is possible to evaluate multiple models with multiple evaluation metrics in one command. In addition, multi-threading can be enabled (see **Tutorial 5** for more details). The method to run evaluations with a `Task` object is called `evaluate_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mhm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluation.Evaluation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_threads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Evaluates models using one or multiple evaluation metrics\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*args: Evaluation\n",
       "    Evaluation objects that will be applied to the models\n",
       "n_threads : int, optional\n",
       "    Number of threads used for model evaluation (default is 1, which\n",
       "    deactivates parallelization)\n",
       "\n",
       "Returns\n",
       "-------\n",
       "None\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/src/homelette/homelette/organization.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hm.Task.evaluate_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running dope and soap at the same time\n",
    "t.evaluate_models(hm.evaluation.Evaluation_dope,\n",
    "                  hm.evaluation.Evaluation_soap_protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running evaluations, output of all `Model.evaluation` can be compiled to a `pandas` data frame as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tag</th>\n",
       "      <th>routine</th>\n",
       "      <th>dope</th>\n",
       "      <th>dope_z_score</th>\n",
       "      <th>soap_protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modeller_1.pdb</td>\n",
       "      <td>modeller</td>\n",
       "      <td>automodel_default</td>\n",
       "      <td>-7216.856445</td>\n",
       "      <td>-1.521113</td>\n",
       "      <td>-44164.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modeller_2.pdb</td>\n",
       "      <td>modeller</td>\n",
       "      <td>automodel_default</td>\n",
       "      <td>-7274.457520</td>\n",
       "      <td>-1.576995</td>\n",
       "      <td>-45670.472656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>modeller_3.pdb</td>\n",
       "      <td>modeller</td>\n",
       "      <td>automodel_default</td>\n",
       "      <td>-7126.735352</td>\n",
       "      <td>-1.433681</td>\n",
       "      <td>-43398.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modeller_4.pdb</td>\n",
       "      <td>modeller</td>\n",
       "      <td>automodel_default</td>\n",
       "      <td>-7225.522461</td>\n",
       "      <td>-1.529520</td>\n",
       "      <td>-42942.808594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modeller_5.pdb</td>\n",
       "      <td>modeller</td>\n",
       "      <td>automodel_default</td>\n",
       "      <td>-7128.661621</td>\n",
       "      <td>-1.435550</td>\n",
       "      <td>-41418.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>altmod_1.pdb</td>\n",
       "      <td>altmod</td>\n",
       "      <td>altmod_default</td>\n",
       "      <td>-8148.456055</td>\n",
       "      <td>-2.424912</td>\n",
       "      <td>-53440.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>altmod_2.pdb</td>\n",
       "      <td>altmod</td>\n",
       "      <td>altmod_default</td>\n",
       "      <td>-8187.364258</td>\n",
       "      <td>-2.462659</td>\n",
       "      <td>-49991.304688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>altmod_3.pdb</td>\n",
       "      <td>altmod</td>\n",
       "      <td>altmod_default</td>\n",
       "      <td>-8202.568359</td>\n",
       "      <td>-2.477409</td>\n",
       "      <td>-53909.824219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>altmod_4.pdb</td>\n",
       "      <td>altmod</td>\n",
       "      <td>altmod_default</td>\n",
       "      <td>-8170.016602</td>\n",
       "      <td>-2.445829</td>\n",
       "      <td>-52228.964844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>altmod_5.pdb</td>\n",
       "      <td>altmod</td>\n",
       "      <td>altmod_default</td>\n",
       "      <td>-8145.944336</td>\n",
       "      <td>-2.422475</td>\n",
       "      <td>-50776.855469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model       tag            routine         dope  dope_z_score  \\\n",
       "0  modeller_1.pdb  modeller  automodel_default -7216.856445     -1.521113   \n",
       "1  modeller_2.pdb  modeller  automodel_default -7274.457520     -1.576995   \n",
       "2  modeller_3.pdb  modeller  automodel_default -7126.735352     -1.433681   \n",
       "3  modeller_4.pdb  modeller  automodel_default -7225.522461     -1.529520   \n",
       "4  modeller_5.pdb  modeller  automodel_default -7128.661621     -1.435550   \n",
       "5    altmod_1.pdb    altmod     altmod_default -8148.456055     -2.424912   \n",
       "6    altmod_2.pdb    altmod     altmod_default -8187.364258     -2.462659   \n",
       "7    altmod_3.pdb    altmod     altmod_default -8202.568359     -2.477409   \n",
       "8    altmod_4.pdb    altmod     altmod_default -8170.016602     -2.445829   \n",
       "9    altmod_5.pdb    altmod     altmod_default -8145.944336     -2.422475   \n",
       "\n",
       "   soap_protein  \n",
       "0 -44164.437500  \n",
       "1 -45670.472656  \n",
       "2 -43398.992188  \n",
       "3 -42942.808594  \n",
       "4 -41418.894531  \n",
       "5 -53440.839844  \n",
       "6 -49991.304688  \n",
       "7 -53909.824219  \n",
       "8 -52228.964844  \n",
       "9 -50776.855469  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the combination of different evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes it is useful to use different metrics to evaluate models. However, that produces the problem of having multiple metrics to base a decision on. There are multiple solutions to this problem, all of them with their own advantages and disadvantes. We want to mention the combination of z-scores of the different metrics and the combination of metrics by [borda count](https://en.wikipedia.org/wiki/Borda_count). \n",
    "\n",
    "In the following, we show how to combine multiple scores to one borda score. In short, borda count is an agglomeration of ranks in the different individual metrics to one score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "Be careful because, for some metrics, lower values are better (DOPE, SOAP, MolProbity), but for others higher values are better (QMEAN).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dope</th>\n",
       "      <th>dope_z_score</th>\n",
       "      <th>soap_protein</th>\n",
       "      <th>rank_dope</th>\n",
       "      <th>rank_soap</th>\n",
       "      <th>points_dope</th>\n",
       "      <th>points_soap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modeller_1.pdb</td>\n",
       "      <td>-7216.856445</td>\n",
       "      <td>-1.521113</td>\n",
       "      <td>-44164.437500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modeller_2.pdb</td>\n",
       "      <td>-7274.457520</td>\n",
       "      <td>-1.576995</td>\n",
       "      <td>-45670.472656</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>modeller_3.pdb</td>\n",
       "      <td>-7126.735352</td>\n",
       "      <td>-1.433681</td>\n",
       "      <td>-43398.992188</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modeller_4.pdb</td>\n",
       "      <td>-7225.522461</td>\n",
       "      <td>-1.529520</td>\n",
       "      <td>-42942.808594</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modeller_5.pdb</td>\n",
       "      <td>-7128.661621</td>\n",
       "      <td>-1.435550</td>\n",
       "      <td>-41418.894531</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>altmod_1.pdb</td>\n",
       "      <td>-8148.456055</td>\n",
       "      <td>-2.424912</td>\n",
       "      <td>-53440.839844</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>altmod_2.pdb</td>\n",
       "      <td>-8187.364258</td>\n",
       "      <td>-2.462659</td>\n",
       "      <td>-49991.304688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>altmod_3.pdb</td>\n",
       "      <td>-8202.568359</td>\n",
       "      <td>-2.477409</td>\n",
       "      <td>-53909.824219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>altmod_4.pdb</td>\n",
       "      <td>-8170.016602</td>\n",
       "      <td>-2.445829</td>\n",
       "      <td>-52228.964844</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>altmod_5.pdb</td>\n",
       "      <td>-8145.944336</td>\n",
       "      <td>-2.422475</td>\n",
       "      <td>-50776.855469</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model         dope  dope_z_score  soap_protein  rank_dope  \\\n",
       "0  modeller_1.pdb -7216.856445     -1.521113 -44164.437500        8.0   \n",
       "1  modeller_2.pdb -7274.457520     -1.576995 -45670.472656        6.0   \n",
       "2  modeller_3.pdb -7126.735352     -1.433681 -43398.992188       10.0   \n",
       "3  modeller_4.pdb -7225.522461     -1.529520 -42942.808594        7.0   \n",
       "4  modeller_5.pdb -7128.661621     -1.435550 -41418.894531        9.0   \n",
       "5    altmod_1.pdb -8148.456055     -2.424912 -53440.839844        4.0   \n",
       "6    altmod_2.pdb -8187.364258     -2.462659 -49991.304688        2.0   \n",
       "7    altmod_3.pdb -8202.568359     -2.477409 -53909.824219        1.0   \n",
       "8    altmod_4.pdb -8170.016602     -2.445829 -52228.964844        3.0   \n",
       "9    altmod_5.pdb -8145.944336     -2.422475 -50776.855469        5.0   \n",
       "\n",
       "   rank_soap  points_dope  points_soap  \n",
       "0        7.0          2.0          3.0  \n",
       "1        6.0          4.0          4.0  \n",
       "2        8.0          0.0          2.0  \n",
       "3        9.0          3.0          1.0  \n",
       "4       10.0          1.0          0.0  \n",
       "5        2.0          6.0          8.0  \n",
       "6        5.0          8.0          5.0  \n",
       "7        1.0          9.0          9.0  \n",
       "8        3.0          7.0          7.0  \n",
       "9        4.0          5.0          6.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = t.get_evaluation()\n",
    "df = df.drop(labels=['routine', 'tag'], axis=1)\n",
    "\n",
    "# rank by dope and soap\n",
    "df['rank_dope'] = df['dope'].rank()\n",
    "df['rank_soap'] = df['soap_protein'].rank()\n",
    "\n",
    "# calculate points based on rank\n",
    "n = df.shape[0]\n",
    "df['points_dope'] = n - df['rank_dope']\n",
    "df['points_soap'] = n - df['rank_soap']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dope</th>\n",
       "      <th>dope_z_score</th>\n",
       "      <th>soap_protein</th>\n",
       "      <th>borda_score</th>\n",
       "      <th>borda_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>altmod_3.pdb</td>\n",
       "      <td>-8202.568359</td>\n",
       "      <td>-2.477409</td>\n",
       "      <td>-53909.824219</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>altmod_1.pdb</td>\n",
       "      <td>-8148.456055</td>\n",
       "      <td>-2.424912</td>\n",
       "      <td>-53440.839844</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>altmod_4.pdb</td>\n",
       "      <td>-8170.016602</td>\n",
       "      <td>-2.445829</td>\n",
       "      <td>-52228.964844</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>altmod_2.pdb</td>\n",
       "      <td>-8187.364258</td>\n",
       "      <td>-2.462659</td>\n",
       "      <td>-49991.304688</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>altmod_5.pdb</td>\n",
       "      <td>-8145.944336</td>\n",
       "      <td>-2.422475</td>\n",
       "      <td>-50776.855469</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modeller_2.pdb</td>\n",
       "      <td>-7274.457520</td>\n",
       "      <td>-1.576995</td>\n",
       "      <td>-45670.472656</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modeller_1.pdb</td>\n",
       "      <td>-7216.856445</td>\n",
       "      <td>-1.521113</td>\n",
       "      <td>-44164.437500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modeller_4.pdb</td>\n",
       "      <td>-7225.522461</td>\n",
       "      <td>-1.529520</td>\n",
       "      <td>-42942.808594</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>modeller_3.pdb</td>\n",
       "      <td>-7126.735352</td>\n",
       "      <td>-1.433681</td>\n",
       "      <td>-43398.992188</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modeller_5.pdb</td>\n",
       "      <td>-7128.661621</td>\n",
       "      <td>-1.435550</td>\n",
       "      <td>-41418.894531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model         dope  dope_z_score  soap_protein  borda_score  \\\n",
       "7    altmod_3.pdb -8202.568359     -2.477409 -53909.824219         18.0   \n",
       "5    altmod_1.pdb -8148.456055     -2.424912 -53440.839844         14.0   \n",
       "8    altmod_4.pdb -8170.016602     -2.445829 -52228.964844         14.0   \n",
       "6    altmod_2.pdb -8187.364258     -2.462659 -49991.304688         13.0   \n",
       "9    altmod_5.pdb -8145.944336     -2.422475 -50776.855469         11.0   \n",
       "1  modeller_2.pdb -7274.457520     -1.576995 -45670.472656          8.0   \n",
       "0  modeller_1.pdb -7216.856445     -1.521113 -44164.437500          5.0   \n",
       "3  modeller_4.pdb -7225.522461     -1.529520 -42942.808594          4.0   \n",
       "2  modeller_3.pdb -7126.735352     -1.433681 -43398.992188          2.0   \n",
       "4  modeller_5.pdb -7128.661621     -1.435550 -41418.894531          1.0   \n",
       "\n",
       "   borda_rank  \n",
       "7         1.0  \n",
       "5         2.5  \n",
       "8         2.5  \n",
       "6         4.0  \n",
       "9         5.0  \n",
       "1         6.0  \n",
       "0         7.0  \n",
       "3         8.0  \n",
       "2         9.0  \n",
       "4        10.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate borda score and borda rank\n",
    "df['borda_score'] = df['points_dope'] + df['points_soap']\n",
    "df['borda_rank'] = df['borda_score'].rank(ascending=False)\n",
    "\n",
    "df = df.drop(labels=['rank_dope', 'rank_soap', 'points_dope', 'points_soap'], axis=1)\n",
    "df.sort_values(by='borda_rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, according to a combination of DOPE and SOAP scores by borda count, the model *altmod_5.pdb* is the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now familiar with using the implemented evaluation features of `homelette`. For further reading, please consider checking out the other tutorials:\n",
    "\n",
    "- **Tutorial 1**: Learn about the basics of `homelette`.\n",
    "- **Tutorial 2**: Learn more about already implemented routines for homology modelling.\n",
    "- **Tutorial 4**: Learn about extending `homelette`'s functionality by defining your own modelling routines and evaluation metrics.\n",
    "- **Tutorial 5**: Learn about how to use parallelization in order to generate and evaluate models more efficiently.\n",
    "- **Tutorial 6**: Learn about modelling protein complexes.\n",
    "- **Tutorial 7**: Learn about assembling custom pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Shen, M., & Sali, A. (2006). Statistical potential for assessment and prediction of protein structures. Protein Science, 15(11), 2507â€“2524. https://doi.org/10.1110/ps.062416606\n",
    "\n",
    "[2] Dong, G. Q., Fan, H., Schneidman-Duhovny, D., Webb, B., Sali, A., & Tramontano, A. (2013). Optimized atomic statistical potentials: Assessment of protein interfaces and loops. Bioinformatics, 29(24), 3158â€“3166. https://doi.org/10.1093/bioinformatics/btt560\n",
    "\n",
    "[3] Benkert, P., Tosatto, S. C. E., & Schomburg, D. (2008). QMEAN: A comprehensive scoring function for model quality assessment. Proteins: Structure, Function and Genetics, 71(1), 261â€“277. https://doi.org/10.1002/prot.21715\n",
    "\n",
    "[4] Benkert, P., Biasini, M., & Schwede, T. (2011). Toward the estimation of the absolute quality of individual protein structure models. Bioinformatics, 27(3), 343â€“350. https://doi.org/10.1093/bioinformatics/btq662\n",
    "\n",
    "[5] Studer, G., Rempfer, C., Waterhouse, A. M., Gumienny, R., Haas, J., & Schwede, T. (2020). QMEANDisCo-distance constraints applied on model quality estimation. Bioinformatics, 36(6), 1765â€“1771. https://doi.org/10.1093/bioinformatics/btz828\n",
    "\n",
    "[6] Davis, I. W., Leaver-Fay, A., Chen, V. B., Block, J. N., Kapral, G. J., Wang, X., Murray, L. W., Arendall, W. B., Snoeyink, J., Richardson, J. S., & Richardson, D. C. (2007). MolProbity: all-atom contacts and structure validation for proteins and nucleic acids. Nucleic Acids Research, 35(suppl_2), W375â€“W383. https://doi.org/10.1093/NAR/GKM216\n",
    "\n",
    "[7] Chen, V. B., Arendall, W. B., Headd, J. J., Keedy, D. A., Immormino, R. M., Kapral, G. J., Murray, L. W., Richardson, J. S., & Richardson, D. C. (2010). MolProbity: All-atom structure validation for macromolecular crystallography. Acta Crystallographica Section D: Biological Crystallography, 66(1), 12â€“21. https://doi.org/10.1107/S0907444909042073\n",
    "\n",
    "[8] Williams, C. J., Headd, J. J., Moriarty, N. W., Prisant, M. G., Videau, L. L., Deis, L. N., Verma, V., Keedy, D. A., Hintze, B. J., Chen, V. B., Jain, S., Lewis, S. M., Arendall, W. B., Snoeyink, J., Adams, P. D., Lovell, S. C., Richardson, J. S., & Richardson, D. C. (2018). MolProbity: More and better reference data for improved all-atom structure validation. Protein Science, 27(1), 293â€“315. https://doi.org/10.1002/pro.3330\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "homelette           1.0\n",
      "pandas              0.25.3\n",
      "session_info        1.0.0\n",
      "-----\n",
      "PIL                         7.0.0\n",
      "altmod                      NA\n",
      "anyio                       NA\n",
      "attr                        19.3.0\n",
      "babel                       2.9.1\n",
      "backcall                    0.2.0\n",
      "certifi                     2021.05.30\n",
      "chardet                     3.0.4\n",
      "charset_normalizer          2.0.4\n",
      "cycler                      0.10.0\n",
      "cython_runtime              NA\n",
      "dateutil                    2.7.3\n",
      "debugpy                     1.4.1\n",
      "decorator                   4.4.2\n",
      "entrypoints                 0.3\n",
      "idna                        3.2\n",
      "ipykernel                   6.3.1\n",
      "ipython_genutils            0.2.0\n",
      "jedi                        0.18.0\n",
      "jinja2                      3.0.1\n",
      "json5                       NA\n",
      "jsonschema                  3.2.0\n",
      "jupyter_server              1.10.2\n",
      "jupyterlab_server           2.8.0\n",
      "kiwisolver                  1.0.1\n",
      "markupsafe                  2.0.1\n",
      "matplotlib                  3.1.2\n",
      "modeller                    10.1\n",
      "mpl_toolkits                NA\n",
      "nbclassic                   NA\n",
      "nbformat                    5.1.3\n",
      "numexpr                     2.7.1\n",
      "numpy                       1.17.4\n",
      "ost                         2.2.0\n",
      "packaging                   20.3\n",
      "parso                       0.8.2\n",
      "pexpect                     4.8.0\n",
      "pickleshare                 0.7.5\n",
      "pkg_resources               NA\n",
      "prometheus_client           NA\n",
      "promod3                     3.2.0\n",
      "prompt_toolkit              3.0.20\n",
      "ptyprocess                  0.7.0\n",
      "pvectorc                    NA\n",
      "pydev_ipython               NA\n",
      "pydevconsole                NA\n",
      "pydevd                      2.4.1\n",
      "pydevd_concurrency_analyser NA\n",
      "pydevd_file_utils           NA\n",
      "pydevd_plugins              NA\n",
      "pydevd_tracing              NA\n",
      "pygments                    2.10.0\n",
      "pyparsing                   2.4.6\n",
      "pyrsistent                  NA\n",
      "pytz                        2019.3\n",
      "qmean                       NA\n",
      "requests                    2.26.0\n",
      "send2trash                  NA\n",
      "sitecustomize               NA\n",
      "six                         1.14.0\n",
      "sniffio                     1.2.0\n",
      "storemagic                  NA\n",
      "swig_runtime_data4          NA\n",
      "terminado                   0.12.1\n",
      "tornado                     6.1\n",
      "traitlets                   5.1.0\n",
      "urllib3                     1.26.6\n",
      "wcwidth                     NA\n",
      "websocket                   1.2.1\n",
      "zmq                         22.2.1\n",
      "-----\n",
      "IPython             7.27.0\n",
      "jupyter_client      7.0.2\n",
      "jupyter_core        4.7.1\n",
      "jupyterlab          3.1.10\n",
      "notebook            6.4.3\n",
      "-----\n",
      "Python 3.8.10 (default, Jun  2 2021, 10:49:15) [GCC 9.4.0]\n",
      "Linux-4.15.0-147-generic-x86_64-with-glibc2.29\n",
      "-----\n",
      "Session information updated at 2021-09-07 15:44\n"
     ]
    }
   ],
   "source": [
    "# session info\n",
    "import session_info\n",
    "session_info.show(html = False, dependencies = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
